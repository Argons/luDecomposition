<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Ludecomposition : LU decomposition of a large matrix using OpenMP and MPI" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Ludecomposition</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/adilansari/luDecomposition">View on GitHub</a>

          <h1 id="project_title">Ludecomposition</h1>
          <h2 id="project_tagline">LU decomposition of a large matrix using OpenMP and MPI</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/adilansari/luDecomposition/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/adilansari/luDecomposition/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a name="parallel-implementation-of-lu-decomposition" class="anchor" href="#parallel-implementation-of-lu-decomposition"><span class="octicon octicon-link"></span></a>Parallel Implementation of LU decomposition</h1>

<h3>
<a name="basics" class="anchor" href="#basics"><span class="octicon octicon-link"></span></a>Basics</h3>

<h1></h1>

<ul>
<li><p>Root directory contains three sub-directories namely ’Sequential’,
’OpenMP’ and ’MPI’.</p></li>
<li><p>Each subdirectory has source code in the form of ** ’*.c’** file.</p></li>
<li><p>Matrix is generated in a manner that it decomposes into a L and U
containing only 1s and 0s.</p></li>
<li><p>To submit jobs for various configurations run <strong>’./submit.sh’</strong> on
terminal. This will automatically submit all the jobs in the
subdirectory to the <strong>general-compute</strong> queue of the ccr cluster.</p></li>
<li><p>Outputs are generated in the <strong>output.txt</strong> file. <em>Sample outputs
are included</em>.</p></li>
<li><p>In the corresponding subdirectory run <strong>./plot.sh</strong> on the linux
terminal to generate a graphical visualization of the output.
<em>gnuplot is required to generate graph</em>.</p></li>
<li><p>Graphs are generated as <strong>’Plot.pdf’</strong>. <em>Please wait for the job run
to finish and outputs to accumulate</em>.</p></li>
</ul><h3>
<a name="sequential-implementation" class="anchor" href="#sequential-implementation"><span class="octicon octicon-link"></span></a>Sequential Implementation</h3>

<h1></h1>

<ul>
<li><p>Gaussian elimination algorithm was implemented that sequentially
decomposes the square matrix.</p></li>
<li><p>Algorithm was evaluated on input matrix size of 1000, 5000, 10000,
20000.</p></li>
<li><p>Time taken to decompose the matrix grew exponentially with the
increase in size.</p></li>
<li><p>Since, this was a sequential implementation increase in compute
nodes won’t do anything.</p></li>
<li><p>Since I was using Gaussian elimination that computes L and U
matrices separately, I ran <strong>out of memory</strong> when matrix size of
50,000 was tried. This implementation makes two copies of the matrix
of same size as input.</p></li>
</ul><p><img src="Sequential/Plot.png" alt="Sequential Decomposition Algorithm"></p>

<h3>
<a name="openmp-implementation" class="anchor" href="#openmp-implementation"><span class="octicon octicon-link"></span></a>OpenMP Implementation</h3>

<h1></h1>

<ul>
<li><p>Gaussian elimination algorithm was implemented that uses the block
wise decomposition in parallel.</p></li>
<li><p>The <strong>for</strong> loops are parallelized in a manner that blocks of
matrices are decomposed by dividing the work among parallel threads.</p></li>
<li><p>Algorithm was evaluated for input matrix of sizes 1000, 5000, 10000,
20000 with a combination of 2, 4, 8, 16, 32 threads executing in
parallel.</p></li>
<li><p>On a fixed workload the decompostion was faster when more threads
are executing in parallel. The execution was comparatively faster on
larger workload due to the fact, parallelism was more effective.</p></li>
<li><p>For a fixed number of cores the time increased exponentially with
increase in matrix size.</p></li>
<li><p>The parallelism was ineffective on relatively smaller loads.</p></li>
<li><p>Since I was using Gaussian elimination that computes L and U
matrices separately, I ran <strong>out of memory</strong> when matrix size of
50,000 was tried. This implementation makes two copies of the matrix
of same size as input.</p></li>
</ul><p><img src="OpenMP/Plot.png" alt="OpenMP Decomposition Algorithm"></p>

<h3>
<a name="mpi-implementation" class="anchor" href="#mpi-implementation"><span class="octicon octicon-link"></span></a>MPI Implementation</h3>

<h1></h1>

<ul>
<li><p>Cyclic distribution was used to accomplish LU factorization of the
input square matrix.</p></li>
<li><p>Each node is responsible for computing its own block and broadcast
the result to rest of the nodes.</p></li>
<li><p>Algorithm was evaluated for input matrix of sizes 1000, 5000, 10000
with a combination of 8, 16, 32 compute nodes working in parallel.</p></li>
<li><p>For a fixed number of compute nodes the algorithm showed uniform
behavior.</p></li>
<li><p>For fixed workload the parallelism was more effective for larger
workloads on maximum compute nodes.</p></li>
</ul><p><img src="MPI/Plot.png" alt="MPI Decomposition Algorithm"></p>

<h1>
<a name="comparison" class="anchor" href="#comparison"><span class="octicon octicon-link"></span></a>Comparison</h1>

<ul>
<li>
<p>Since, MPI involves communication overhead between different nodes,
it was slower as compared to OpenMP.</p>

<p><img src="Graphs/omp_mpi_core_time.png" alt="OpenMP vs. MPI"></p>
</li>
<li>
<p>As expected sequential algorithm turns out to be the worst performer
of the three.</p>

<p><img src="Graphs/omp_mpi_seq_siz_time.png" alt="Sequential vs. OpenMP vs.MPI"></p>
</li>
</ul><h3>
<a name="scalability" class="anchor" href="#scalability"><span class="octicon octicon-link"></span></a>Scalability</h3>

<h1></h1>

<p>LU factorization algorithm has a great extent of parallelization when
scaled appropriately.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Ludecomposition maintained by <a href="https://github.com/adilansari">adilansari</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
